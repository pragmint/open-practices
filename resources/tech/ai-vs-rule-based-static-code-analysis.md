# AI vs Rule-based Static Code Analysis by Kendrick Curtis

Resource type: Video

https://www.youtube.com/watch?v=hkd5uk7J-qo

## What it’s about

Kendrick shows what happens when you throw GPT at static code analysis and compares it to the old-school rule-based tools. The demo is equal parts fun and painful: wrong line numbers, inconsistent results, slow runs, and plenty of noise. But he also shows where AI could shine — explaining issues better, suggesting fixes, and maybe making devs’ lives easier.

## Why it’s worth watching

If you’ve ever cursed at lint warnings or doubted whether AI tools are ready for prime time, this talk hits close to home. It’s not a sales pitch — it’s more of a reality check with some hopeful takeaways.

## Pause and Ponder

01:13 – Beer vs AI analogy - What “bad decisions” do we risk if we lean too hard on AI tools?
04:16 – Wrong line numbers - Is noisy or misleading feedback worse than no feedback at all?
06:13 – Different run, different results - Could we trust this in a compliance/security pipeline?
08:18 – Prompt engineering headaches - Do we really want to replace maintaining rulesets with maintaining prompts?
13:40 – AI for explanations/fixes - Would we trust AI’s explanation of a bug more than its ability to find the bug?
15:01 – Cost and speed - Regex vs AI: if regex is faster, cheaper, and reliable, what’s the real use case for AI here?
20:00 – GitHub auto-fix suggestions - How comfortable would we be letting AI propose (or even auto-commit) fixes?

## Takeaway

AI isn’t ready to replace static analyzers, but AI tools that delegate to static analyzers might be more useful than just using static analyzers. Think of AI less as the cop writing you a ticket and more as the buddy explaining why you got pulled over.
