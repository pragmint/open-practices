# Where AI Meets Code by Michael Feathers

Resource type: Video

https://www.youtube.com/watch?v=g9m3R0NMJ1Y

## What it’s about

Michael Feathers (aka the "Working Effectively with Legacy Code" guy) explores how AI can be used with code, not just bolted into products. Instead of focusing on hype or tool demos, he shares mental models, experiments, and techniques for using LLMs to reason about code, generate different "views" of it (math, diagrams, translations), and spark design ideas. The talk’s vibe: curious, playful, and practical.

## Why it’s worth watching

It’s not another "Copilot vs. X" comparison. This is about how to think when pairing with AI. Tons of ideas you can steal for experimentation, code exploration, and better design discussions with your team.

## Pause and Ponder

02:31 – The "surfacing model" - When you mention a concept in a prompt, related concepts get "pulled along." How does that explain both the magic and the weird failures of LLMs?

06:12 – Lost in the middle - Models remember the start and end of a session better than the middle. How do we see this same "recency/primacy effect" in our own team conversations?

11:01 – Projections - What happens when you look at code from a completely different angle (math, state machines, another language)? Could we use this to spot bugs or design flaws faster?

15:00 – Lensing - If you ask "show me the top 7 responsibilities," then narrow to 4, the model doesn’t just drop 3 — it re-evaluates. How might that trick help us clarify big messy classes?

18:11 – Side-by-sides - Solve something yourself, then ask the model to solve it too. How often would comparing answers sharpen your own thinking?

23:03 – "Pigeon languages" & waywords - Making up shorthand words in a session (like inate or chainify) to guide the model. Would inventing our own vocab speed up how we collaborate with AI?

34:01 – Review fatigue - Do we have enough patience to constantly double-check AI output? How can we avoid burning out on endless "is this good enough?" reviews?

36:50 – Small chunks rule - Why is "work in small slices" even more critical when using AI?

37:56 – Generating tests - Should we treat AI-generated tests as disposable characterizations, not permanent assets?

40:00 – Rigor vs. creativity - If hallucinations are "just creativity," are we leaning too hard on the wrong strengths of LLMs?

## Takeaway

AI isn’t here to replace us. It’s more like a brainstorming buddy that sees code from angles we normally don’t. Use it to stretch your thinking, not to hand over the wheel.
